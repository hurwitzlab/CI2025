{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cce118b",
   "metadata": {},
   "source": [
    "# CICF Week 12\n",
    "\n",
    "This notebook builds a neural network model for predicting survival using the Titanic dataset from the previous week.\n",
    "\n",
    "This notebook borrows from Jeremy Howard's execellent course, [lesson 5](https://github.com/fastai/course22/blob/master/05-linear-model-and-neural-net-from-scratch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c7fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2a4d6",
   "metadata": {},
   "source": [
    "Before we look at the Titanic dataset, we are first going to look at how PyTorch can caluclate deriatives.\n",
    "PyTorch is a library extending the NumPy arrays that adds many functions to faciliate working with neural networks. It can also move calculations to a GPU for speed, something that NumPy doesn't do itself.\n",
    "\n",
    "The fundamental PyTorch datatype is the `tensor`. It is similar to an array of numbers.\n",
    "Tensors have a _rank_, which is akin to the number of dimensions it has, and a _shape_ which is the number of columns it has in each dimension.\n",
    "\n",
    "The key thing for tensors is that PyTorch will remember how they are used in a computation so that it can calculate the derivative for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d8c23afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return x**2\n",
    "\n",
    "a = torch.tensor(3.)\n",
    "a.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11950458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = f(a)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e69e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f07ba7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../week11/titanic.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87f260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77bfc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2d3a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>2.962246</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>2.187218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.240917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch        Fare     LogFare  Sex_female    Sex_male    Pclass_1  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838   28.566970    0.523008    0.381594   32.204208    2.962246    0.352413    0.647587    0.242424   \n",
       "std     257.353842    0.486592   13.199572    1.102743    0.806057   49.693429    0.969048    0.477990    0.477990    0.428790   \n",
       "min       1.000000    0.000000    0.420000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     223.500000    0.000000   22.000000    0.000000    0.000000    7.910400    2.187218    0.000000    0.000000    0.000000   \n",
       "50%     446.000000    0.000000   24.000000    0.000000    0.000000   14.454200    2.737881    0.000000    1.000000    0.000000   \n",
       "75%     668.500000    1.000000   35.000000    1.000000    0.000000   31.000000    3.465736    1.000000    1.000000    0.000000   \n",
       "max     891.000000    1.000000   80.000000    8.000000    6.000000  512.329200    6.240917    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Pclass_2    Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
       "mean     0.206510    0.551066    0.188552    0.086420    0.722783  \n",
       "std      0.405028    0.497665    0.391372    0.281141    0.447876  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    1.000000    0.000000    0.000000    1.000000  \n",
       "75%      0.000000    1.000000    0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3201971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03156d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=float)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e41f6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "t_dep = tensor(df.Survived)\n",
    "cols=['Age','SibSp','Parch','LogFare','Sex_male','Sex_female','Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S']\n",
    "t_indep=tensor(df[cols].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46e1441c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb334d",
   "metadata": {},
   "source": [
    "Normalize each column to only have values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecd67371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,_ = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363185b",
   "metadata": {},
   "source": [
    "We are going to make the same model that we used in the spreadsheet: two sets of weights which are multiplied by the independent columns. Then a non-negative function (aka $max(0,x)$ aka ReLU), and then added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0269961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(442)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(12,2, dtype=float),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f26565ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.sum(torch.abs(calc_preds(t_indep)-t_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37d6e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8fe897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer  =torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "020f65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca62b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "train_split,test_split = RandomSplitter(seed=42)(df)\n",
    "train_indep, test_indep = t_indep[train_split], t_indep[test_split]\n",
    "train_dep, test_dep = t_dep[train_split], t_dep[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ae3a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nloops):\n",
    "    for i in range(nloops):\n",
    "        optimizer.zero_grad()\n",
    "        pred = calc_preds(train_indep)\n",
    "        loss = torch.mean(torch.abs(pred - train_dep))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loop: {i}, loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31d4b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.212425\n",
      "loop: 1, loss: 0.212297\n",
      "loop: 2, loss: 0.212170\n",
      "loop: 3, loss: 0.212043\n",
      "loop: 4, loss: 0.211916\n",
      "loop: 5, loss: 0.211788\n",
      "loop: 6, loss: 0.211661\n",
      "loop: 7, loss: 0.211534\n",
      "loop: 8, loss: 0.211407\n",
      "loop: 9, loss: 0.211279\n"
     ]
    }
   ],
   "source": [
    "train_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da0f7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0836, -0.1562, -0.0925,  0.1516, -0.7237,  0.6614,  0.3275,  0.3220, -0.9256, -0.0205,  0.1028,  0.0375],\n",
      "        [-0.1980,  0.1385, -0.2328, -0.4433, -0.6048,  0.3697, -0.4307, -0.3428,  0.3637,  0.2890,  0.3146, -0.6060]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0325, 0.0223], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c46e5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8258426785469055\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57d6a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee5e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return torch.sigmoid(y.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14201ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.454624\n",
      "loop: 1, loss: 0.454620\n",
      "loop: 2, loss: 0.454617\n",
      "loop: 3, loss: 0.454613\n",
      "loop: 4, loss: 0.454610\n",
      "loop: 5, loss: 0.454606\n",
      "loop: 6, loss: 0.454602\n",
      "loop: 7, loss: 0.454599\n",
      "loop: 8, loss: 0.454595\n",
      "loop: 9, loss: 0.454592\n",
      "loop: 10, loss: 0.454588\n",
      "loop: 11, loss: 0.454585\n",
      "loop: 12, loss: 0.454581\n",
      "loop: 13, loss: 0.454578\n",
      "loop: 14, loss: 0.454574\n",
      "loop: 15, loss: 0.454570\n",
      "loop: 16, loss: 0.454567\n",
      "loop: 17, loss: 0.454563\n",
      "loop: 18, loss: 0.454560\n",
      "loop: 19, loss: 0.454556\n"
     ]
    }
   ],
   "source": [
    "train_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f361cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8258426785469055\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9bcd8730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0826, -0.1561, -0.0923,  0.1532, -0.7237,  0.6639,  0.3290,  0.3230, -0.9256, -0.0197,  0.1028,  0.0392],\n",
      "        [-0.1979,  0.1385, -0.2328, -0.4431, -0.6048,  0.3702, -0.4307, -0.3427,  0.3640,  0.2893,  0.3148, -0.6060]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0349, 0.0227], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1185cbfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'LogFare',\n",
       " 'Sex_male',\n",
       " 'Sex_female',\n",
       " 'Pclass_1',\n",
       " 'Pclass_2',\n",
       " 'Pclass_3',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa127ec",
   "metadata": {},
   "source": [
    "Lets try this with a very, _very_ more complicated model.\n",
    "(It addes weights to the final sum step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b1bf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(12,2, dtype=float),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2,1, dtype=float)\n",
    ")\n",
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return y\n",
    "optimizer  =torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "718f10fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.379576\n",
      "loop: 1, loss: 0.379530\n",
      "loop: 2, loss: 0.379484\n",
      "loop: 3, loss: 0.379438\n",
      "loop: 4, loss: 0.379420\n",
      "loop: 5, loss: 0.379578\n",
      "loop: 6, loss: 0.379532\n",
      "loop: 7, loss: 0.379486\n",
      "loop: 8, loss: 0.379440\n",
      "loop: 9, loss: 0.379411\n",
      "loop: 10, loss: 0.379580\n",
      "loop: 11, loss: 0.379534\n",
      "loop: 12, loss: 0.379488\n",
      "loop: 13, loss: 0.379442\n",
      "loop: 14, loss: 0.379402\n",
      "loop: 15, loss: 0.379582\n",
      "loop: 16, loss: 0.379536\n",
      "loop: 17, loss: 0.379490\n",
      "loop: 18, loss: 0.379444\n",
      "loop: 19, loss: 0.379399\n",
      "loop: 20, loss: 0.379576\n",
      "loop: 21, loss: 0.379540\n",
      "loop: 22, loss: 0.379494\n",
      "loop: 23, loss: 0.379448\n",
      "loop: 24, loss: 0.379404\n",
      "loop: 25, loss: 0.379558\n",
      "loop: 26, loss: 0.379545\n",
      "loop: 27, loss: 0.379498\n",
      "loop: 28, loss: 0.379452\n",
      "loop: 29, loss: 0.379407\n",
      "loop: 30, loss: 0.379542\n",
      "loop: 31, loss: 0.379548\n",
      "loop: 32, loss: 0.379501\n",
      "loop: 33, loss: 0.379455\n",
      "loop: 34, loss: 0.379410\n",
      "loop: 35, loss: 0.379529\n",
      "loop: 36, loss: 0.379551\n",
      "loop: 37, loss: 0.379504\n",
      "loop: 38, loss: 0.379458\n",
      "loop: 39, loss: 0.379413\n",
      "loop: 40, loss: 0.379515\n",
      "loop: 41, loss: 0.379554\n",
      "loop: 42, loss: 0.379508\n",
      "loop: 43, loss: 0.379462\n",
      "loop: 44, loss: 0.379416\n",
      "loop: 45, loss: 0.379501\n",
      "loop: 46, loss: 0.379557\n",
      "loop: 47, loss: 0.379511\n",
      "loop: 48, loss: 0.379465\n",
      "loop: 49, loss: 0.379419\n",
      "loop: 50, loss: 0.379488\n",
      "loop: 51, loss: 0.379561\n",
      "loop: 52, loss: 0.379514\n",
      "loop: 53, loss: 0.379468\n",
      "loop: 54, loss: 0.379423\n",
      "loop: 55, loss: 0.379474\n",
      "loop: 56, loss: 0.379564\n",
      "loop: 57, loss: 0.379517\n",
      "loop: 58, loss: 0.379471\n",
      "loop: 59, loss: 0.379426\n",
      "loop: 60, loss: 0.379461\n",
      "loop: 61, loss: 0.379567\n",
      "loop: 62, loss: 0.379520\n",
      "loop: 63, loss: 0.379474\n",
      "loop: 64, loss: 0.379429\n",
      "loop: 65, loss: 0.379447\n",
      "loop: 66, loss: 0.379570\n",
      "loop: 67, loss: 0.379523\n",
      "loop: 68, loss: 0.379477\n",
      "loop: 69, loss: 0.379431\n",
      "loop: 70, loss: 0.379435\n",
      "loop: 71, loss: 0.379573\n",
      "loop: 72, loss: 0.379526\n",
      "loop: 73, loss: 0.379480\n",
      "loop: 74, loss: 0.379434\n",
      "loop: 75, loss: 0.379423\n",
      "loop: 76, loss: 0.379576\n",
      "loop: 77, loss: 0.379529\n",
      "loop: 78, loss: 0.379483\n",
      "loop: 79, loss: 0.379437\n",
      "loop: 80, loss: 0.379410\n",
      "loop: 81, loss: 0.379578\n",
      "loop: 82, loss: 0.379531\n",
      "loop: 83, loss: 0.379485\n",
      "loop: 84, loss: 0.379439\n",
      "loop: 85, loss: 0.379401\n",
      "loop: 86, loss: 0.379580\n",
      "loop: 87, loss: 0.379533\n",
      "loop: 88, loss: 0.379487\n",
      "loop: 89, loss: 0.379441\n",
      "loop: 90, loss: 0.379396\n",
      "loop: 91, loss: 0.379576\n",
      "loop: 92, loss: 0.379537\n",
      "loop: 93, loss: 0.379491\n",
      "loop: 94, loss: 0.379445\n",
      "loop: 95, loss: 0.379400\n",
      "loop: 96, loss: 0.379561\n",
      "loop: 97, loss: 0.379541\n",
      "loop: 98, loss: 0.379494\n",
      "loop: 99, loss: 0.379448\n",
      "loop: 100, loss: 0.379403\n",
      "loop: 101, loss: 0.379546\n",
      "loop: 102, loss: 0.379544\n",
      "loop: 103, loss: 0.379497\n",
      "loop: 104, loss: 0.379451\n",
      "loop: 105, loss: 0.379406\n",
      "loop: 106, loss: 0.379532\n",
      "loop: 107, loss: 0.379547\n",
      "loop: 108, loss: 0.379501\n",
      "loop: 109, loss: 0.379455\n",
      "loop: 110, loss: 0.379409\n",
      "loop: 111, loss: 0.379518\n",
      "loop: 112, loss: 0.379550\n",
      "loop: 113, loss: 0.379504\n",
      "loop: 114, loss: 0.379458\n",
      "loop: 115, loss: 0.379412\n",
      "loop: 116, loss: 0.379505\n",
      "loop: 117, loss: 0.379554\n",
      "loop: 118, loss: 0.379507\n",
      "loop: 119, loss: 0.379461\n",
      "loop: 120, loss: 0.379415\n",
      "loop: 121, loss: 0.379491\n",
      "loop: 122, loss: 0.379557\n",
      "loop: 123, loss: 0.379510\n",
      "loop: 124, loss: 0.379464\n",
      "loop: 125, loss: 0.379419\n",
      "loop: 126, loss: 0.379477\n",
      "loop: 127, loss: 0.379560\n",
      "loop: 128, loss: 0.379513\n",
      "loop: 129, loss: 0.379467\n",
      "loop: 130, loss: 0.379421\n",
      "loop: 131, loss: 0.379465\n",
      "loop: 132, loss: 0.379563\n",
      "loop: 133, loss: 0.379516\n",
      "loop: 134, loss: 0.379470\n",
      "loop: 135, loss: 0.379424\n",
      "loop: 136, loss: 0.379453\n",
      "loop: 137, loss: 0.379566\n",
      "loop: 138, loss: 0.379519\n",
      "loop: 139, loss: 0.379473\n",
      "loop: 140, loss: 0.379427\n",
      "loop: 141, loss: 0.379441\n",
      "loop: 142, loss: 0.379568\n",
      "loop: 143, loss: 0.379522\n",
      "loop: 144, loss: 0.379475\n",
      "loop: 145, loss: 0.379430\n",
      "loop: 146, loss: 0.379429\n",
      "loop: 147, loss: 0.379571\n",
      "loop: 148, loss: 0.379524\n",
      "loop: 149, loss: 0.379478\n",
      "loop: 150, loss: 0.379432\n",
      "loop: 151, loss: 0.379418\n",
      "loop: 152, loss: 0.379574\n",
      "loop: 153, loss: 0.379527\n",
      "loop: 154, loss: 0.379481\n",
      "loop: 155, loss: 0.379435\n",
      "loop: 156, loss: 0.379407\n",
      "loop: 157, loss: 0.379576\n",
      "loop: 158, loss: 0.379529\n",
      "loop: 159, loss: 0.379483\n",
      "loop: 160, loss: 0.379437\n",
      "loop: 161, loss: 0.379397\n",
      "loop: 162, loss: 0.379578\n",
      "loop: 163, loss: 0.379532\n",
      "loop: 164, loss: 0.379485\n",
      "loop: 165, loss: 0.379439\n",
      "loop: 166, loss: 0.379394\n",
      "loop: 167, loss: 0.379570\n",
      "loop: 168, loss: 0.379536\n",
      "loop: 169, loss: 0.379489\n",
      "loop: 170, loss: 0.379443\n",
      "loop: 171, loss: 0.379398\n",
      "loop: 172, loss: 0.379555\n",
      "loop: 173, loss: 0.379539\n",
      "loop: 174, loss: 0.379492\n",
      "loop: 175, loss: 0.379446\n",
      "loop: 176, loss: 0.379401\n",
      "loop: 177, loss: 0.379541\n",
      "loop: 178, loss: 0.379542\n",
      "loop: 179, loss: 0.379495\n",
      "loop: 180, loss: 0.379449\n",
      "loop: 181, loss: 0.379404\n",
      "loop: 182, loss: 0.379527\n",
      "loop: 183, loss: 0.379545\n",
      "loop: 184, loss: 0.379498\n",
      "loop: 185, loss: 0.379452\n",
      "loop: 186, loss: 0.379407\n",
      "loop: 187, loss: 0.379514\n",
      "loop: 188, loss: 0.379548\n",
      "loop: 189, loss: 0.379502\n",
      "loop: 190, loss: 0.379455\n",
      "loop: 191, loss: 0.379410\n",
      "loop: 192, loss: 0.379500\n",
      "loop: 193, loss: 0.379551\n",
      "loop: 194, loss: 0.379505\n",
      "loop: 195, loss: 0.379459\n",
      "loop: 196, loss: 0.379413\n",
      "loop: 197, loss: 0.379488\n",
      "loop: 198, loss: 0.379554\n",
      "loop: 199, loss: 0.379508\n"
     ]
    }
   ],
   "source": [
    "train_model(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "21e5d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5955055952072144\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0d494155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1960, -0.1220,  0.1653, -0.2724, -0.1901, -0.1111,  0.2767,  0.1198, -0.1633,  0.0999,  0.2361, -0.2181],\n",
       "         [-0.2748, -0.2190,  0.0676, -0.1815,  0.0796,  0.2002,  0.2100, -0.1078, -0.2290,  0.2101, -0.1251, -0.1723]], dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1902, -0.0883], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.6278, -0.3675]], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0003], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
